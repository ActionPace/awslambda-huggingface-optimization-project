<h1 id="first-post-about-this-project">First Post about this project</h1>

<p>After about a month of setting up basic concept and executing it, I have reached a milestone and am ready to start sharing my results and plans regarding this project.</p>

<p>Essentially, my goal was to run a fairly extensive optimization test with the goal of running Huggingface language models on AWS Lambda Serverless.</p>

<p>The idea is that hosting these large, relatively slow language models can become expensive on dedicated and GPU equipped dedicated hosts.</p>

<p>If it were possible to make use of the AWS Lambda Serverless environment and utilize all available hardware and optimization tools and techniques, would it be possible to obtain acceptable response time?</p>

<p>This is what I wanted to find out!</p>

<p>After some initial research, I discovered that there are two kinds of CPU architectures available on AWS Lambda:</p>

<p>There is the X86 processor and also the Graviton2 ARM architecture.</p>

<p>According to Amazon, there is a lot of potential power and price savings to be had with this processor.</p>

<p>So, I set out to set up a Optimization Test where I could get response times from a basic Huggingface language model for 2 different architectures and 4 different operating systems.</p>

<p>They are:</p>

<ul>
  <li>X86 (X86_64)</li>
  <li>ARM (aarch64)</li>
</ul>

<p>and</p>

<ul>
  <li>Amazon Linux 2</li>
  <li>Amazon Linux 2022</li>
  <li>Ubuntu 20.04</li>
  <li>Ubuntu 22.04</li>
</ul>
